{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from os import listdir\n",
    "from os.path import join, isfile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model configuration\n",
    "# Encoder\n",
    "input_shape = (128, 128, 3)\n",
    "before_flatten_shape = (8, 8, 64)\n",
    "enc_layer_nums = 4\n",
    "enc_filters = [32, 64, 64, 64]\n",
    "enc_kernel_size = [3, 3, 3, 3]\n",
    "enc_strides = [2, 2, 2, 2]\n",
    "enc_padding = [\"same\"] * enc_layer_nums\n",
    "latent_dim = 200\n",
    "# Decoder\n",
    "dec_layer_nums = 4\n",
    "dec_filters = [64, 64, 32, 3]\n",
    "dec_kernel_size = [3, 3, 3, 3]\n",
    "dec_strides = [2, 2, 2, 2]\n",
    "dec_padding = [\"same\"] * dec_layer_nums\n",
    "# Common\n",
    "drop_rate = 0.25\n",
    "model_config = {\"input_shape\": input_shape,\n",
    "                \"before_flatten_shape\": before_flatten_shape,\n",
    "                \"enc_layer_nums\": enc_layer_nums,\n",
    "                \"enc_filters\": enc_filters,\n",
    "                \"enc_kernel_size\": enc_kernel_size,\n",
    "                \"enc_strides\": enc_strides,\n",
    "                \"enc_padding\": enc_padding,\n",
    "                \"latent_dim\": latent_dim,\n",
    "                \"dec_layer_nums\": dec_layer_nums,\n",
    "                \"dec_filters\": dec_filters,\n",
    "                \"dec_kernel_size\": dec_kernel_size,\n",
    "                \"dec_strides\": dec_strides,\n",
    "                \"dec_padding\": dec_padding,\n",
    "                \"drop_rate\": drop_rate}\n",
    "\n",
    "# Training configuration\n",
    "kl_loss_factor = 0.00001\n",
    "learning_rate = 0.001\n",
    "beta_1 = 0.9\n",
    "beta_2 = 0.999\n",
    "batch_size = 32\n",
    "epochs = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataLoader:\n",
    "    def __init__(self, data_dirs=None, folder_dir=None, reshape=None):\n",
    "        assert data_dirs is not None or folder_dir is not None, \"Either data_dir or folder_dir must provided\"\n",
    "        assert type(reshape) == list or type(reshape) == tuple, \"reshape must be list or tuple of length 2\"\n",
    "        assert len(reshape) == 2, \"reshape must be list or tuple of length 2\"\n",
    "        \n",
    "        # Define properties\n",
    "        self.data_dirs = data_dirs\n",
    "        self.reshape = reshape\n",
    "        \n",
    "        # Get data_dirs\n",
    "        if data_dirs is None and folder_dir is not None:\n",
    "            self.data_dirs = [join(folder_dir, file) for file in listdir(folder_dir) if isfile(join(folder_dir, file))]\n",
    "        \n",
    "    def __call__(self):\n",
    "        # Read image by image\n",
    "        for data_dir in self.data_dirs:\n",
    "            # Load image and convert to numpy\n",
    "            img = Image.open(data_dir)\n",
    "            img = np.asarray(img)\n",
    "            \n",
    "            # Resize image to match with input shape\n",
    "            if self.reshape is not None:\n",
    "                img = cv2.resize(img, self.reshape)\n",
    "            \n",
    "            # Normalization image\n",
    "            img = img / 255.\n",
    "            yield (img, img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataLoader\n",
    "data_loader = DataLoader(folder_dir=\"../datasets/CelebFaces/imgs\", reshape=input_shape[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Generator\n",
    "train_gen = tf.data.Dataset.from_generator(data_loader, (tf.float32, tf.float32), (tf.TensorShape([128, 128, 3]), tf.TensorShape([128, 128, 3])))\n",
    "                                           \n",
    "train_gen = train_gen.shuffle(1000, reshuffle_each_iteration=True)\n",
    "train_gen = train_gen.batch(batch_size, drop_remainder=True)\n",
    "train_gen = train_gen.repeat()\n",
    "train_gen = train_gen.prefetch(tf.data.experimental.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_encoder(config):\n",
    "    # Define input\n",
    "    inputs = tf.keras.Input(shape=config[\"input_shape\"], name=\"encoder_input\")\n",
    "    \n",
    "    # Define layers\n",
    "    x = inputs\n",
    "    for i in range(config[\"enc_layer_nums\"]):\n",
    "        x = tf.keras.layers.Conv2D(filters=config[\"enc_filters\"][i],\n",
    "                                   kernel_size=config[\"enc_kernel_size\"][i],\n",
    "                                   strides=config[\"enc_strides\"][i],\n",
    "                                   padding=config[\"enc_padding\"][i],\n",
    "                                   name=\"encoder_conv_{}\".format(i + 1))(x)\n",
    "        x = tf.keras.layers.BatchNormalization()(x)\n",
    "        x = tf.keras.layers.LeakyReLU()(x)\n",
    "        x = tf.keras.layers.Dropout(config[\"drop_rate\"])(x)\n",
    "    x = tf.keras.layers.Flatten()(x)\n",
    "    \n",
    "    # Define output\n",
    "    mean = tf.keras.layers.Dense(config[\"latent_dim\"], name=\"mean\")(x)\n",
    "    log_var = tf.keras.layers.Dense(config[\"latent_dim\"], name=\"log_var\")(x)\n",
    "    return tf.keras.Model(inputs=inputs, outputs=[mean, log_var], name=\"encoder\")\n",
    "\n",
    "def build_decoder(config):\n",
    "    # Define input\n",
    "    inputs = tf.keras.Input(shape=config[\"latent_dim\"], name=\"decoder_input\")\n",
    "    \n",
    "    # Define layers\n",
    "    x = inputs\n",
    "    x = tf.keras.layers.Dense(np.prod(config[\"before_flatten_shape\"]))(x)\n",
    "    x = tf.keras.layers.Reshape(config[\"before_flatten_shape\"])(x)\n",
    "    for i in range(config[\"dec_layer_nums\"]):\n",
    "        x = tf.keras.layers.Conv2DTranspose(filters=config[\"dec_filters\"][i],\n",
    "                                            kernel_size=config[\"dec_kernel_size\"][i],\n",
    "                                            strides=config[\"dec_strides\"][i],\n",
    "                                            padding=config[\"dec_padding\"][i],\n",
    "                                            name=\"decoder_conv_t_{}\".format(i + 1))(x)\n",
    "        if i < config[\"dec_layer_nums\"] - 1:\n",
    "            x = tf.keras.layers.LeakyReLU()(x)\n",
    "        else:\n",
    "            x = tf.keras.layers.Activation(\"sigmoid\")(x)\n",
    "    \n",
    "    # Define output\n",
    "    outputs = x\n",
    "    return tf.keras.Model(inputs=inputs, outputs=outputs, name=\"decoder\")\n",
    "\n",
    "def sampling(mean, log_var):\n",
    "    epsilon = tf.random.normal(tf.shape(mean), mean=0.0, stddev=1.0)\n",
    "    return mean + tf.math.exp(log_var / 2) * epsilon\n",
    "\n",
    "class Autoencoder(tf.keras.Model):\n",
    "    def __init__(self, config):\n",
    "        super().__init__(self)\n",
    "        self.encoder = build_encoder(config)\n",
    "        self.decoder = build_decoder(config)\n",
    "        self.mean = None\n",
    "        self.log_var = None\n",
    "        \n",
    "    def call(self, x, training=False):\n",
    "        self.mean, self.log_var = self.encoder(x)\n",
    "        latent_vector = sampling(self.mean, self.log_var)\n",
    "        outputs = self.decoder(latent_vector)\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build Autoencoder model\n",
    "model = Autoencoder(model_config)\n",
    "model.build(input_shape=(batch_size, ) + input_shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAELoss(tf.keras.losses.Loss):\n",
    "    def __init__(self, model, kl_loss_factor):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "        self.kl_loss_factor = kl_loss_factor\n",
    "        self.r_loss = tf.keras.losses.MeanSquaredError()\n",
    "        \n",
    "    def kl_loss(self):\n",
    "        mean = self.model.mean\n",
    "        log_var = self.model.log_var\n",
    "        return -0.5 * tf.reduce_sum(1 + log_var - tf.math.square(mean) - tf.math.exp(log_var), axis=1)\n",
    "        \n",
    "    def call(self, y_true, y_pred):\n",
    "        r_loss = self.r_loss(y_true, y_pred)\n",
    "        kl_loss = self.kl_loss() * kl_loss_factor\n",
    "        return r_loss + kl_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 6331 steps\n",
      "Epoch 1/10\n",
      "6331/6331 [==============================] - 1752s 277ms/step - loss: 0.0150\n",
      "Epoch 2/10\n",
      "6331/6331 [==============================] - 1764s 279ms/step - loss: 0.0115\n",
      "Epoch 3/10\n",
      "6331/6331 [==============================] - 1757s 278ms/step - loss: 0.0108\n",
      "Epoch 4/10\n",
      "6331/6331 [==============================] - 1695s 268ms/step - loss: 0.0106\n",
      "Epoch 5/10\n",
      "6331/6331 [==============================] - 1694s 268ms/step - loss: 0.0104\n",
      "Epoch 6/10\n",
      "6331/6331 [==============================] - 1694s 268ms/step - loss: 0.0103\n",
      "Epoch 7/10\n",
      "6331/6331 [==============================] - 1709s 270ms/step - loss: 0.0102\n",
      "Epoch 8/10\n",
      "6331/6331 [==============================] - 1738s 275ms/step - loss: 0.0102\n",
      "Epoch 9/10\n",
      "6331/6331 [==============================] - 1712s 270ms/step - loss: 0.0101\n",
      "Epoch 10/10\n",
      "6331/6331 [==============================] - 1771s 280ms/step - loss: 0.0101\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x638360e50>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compile model\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate, beta_1=beta_1, beta_2=beta_2),\n",
    "              loss=VAELoss(model=model, kl_loss_factor=kl_loss_factor))\n",
    "\n",
    "# Fit model\n",
    "model.fit(train_gen,\n",
    "          steps_per_epoch=len(data_loader.data_dirs) // batch_size,\n",
    "          epochs=epochs,\n",
    "          shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights(\"./save/03_VAE_to_Generate_Faces/model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x63822bd10>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_weights(\"./save/03_VAE_to_Generate_Faces/model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
